---
title: "Robot mobile autonome ROS 2 - Stage YELLOLAB"
startDate: 2024-04-01
endDate: 2024-07-31
summary: "Conception d'un robot mobile avec SLAM et navigation sous ROS 2 - YELLOLAB INPHB Yamoussoukro"
url: ""
cover: "./images/yellolab-robot/cover.png"
tags: ["ROS 2", "C++", "Python", "SLAM", "Navigation", "Raspberry Pi", "Arduino"]
ogImage: "/og-image.webp"
---

## Contexte du projet

**Stage de 2ème année** : D'avril à juillet 2024, j'ai effectué un stage au **laboratoire de fabrication numérique YelloLab de l'INPHB** à Yamoussoukro (Côte d'Ivoire), en tant qu'**ingénieur en conception robotique**.

J'ai travaillé sur la conception d'un **robot mobile autonome**, intégrant des actionneurs, des capteurs et un système de navigation basé sur **ROS 2**. Le développement a été réalisé en **C++ et Python**, avec une architecture embarquée reposant sur un **Raspberry Pi** et une carte **Arduino**.

## Objectifs du stage

- **Architecture ROS 2** : Migration et modernisation vers ROS 2 Humble
- **SLAM avancé** : Implémentation d'algorithmes de cartographie robustes  
- **Navigation autonome** : Planification de trajectoires et évitement d'obstacles
- **Intégration embarquée** : Développement de drivers pour Raspberry Pi et microcontrôleurs
- **Tests terrain** : Validation dans environnements réels sous contraintes

## Architecture technique

### Stack logicielle
```yaml
# Configuration ROS 2
ros2_packages:
  - navigation2
  - slam_toolbox  
  - robot_localization
  - tf2_geometry_msgs
  - sensor_msgs
```

### Matériel intégré
- **Raspberry Pi 4** : Unité de calcul principale (Ubuntu 22.04 + ROS 2 Humble)
- **Microcontrôleurs** : ESP32 pour contrôle bas niveau
- **Capteurs** : Lidar 2D, caméras RGB-D, IMU 9-axis, encodeurs
- **Actionneurs** : Moteurs brushless avec drivers dédiés

## Innovations apportées

### Communication temps réel
- **DDS** : Utilisation du middleware DDS natif de ROS 2
- **QoS profiles** : Optimisation selon criticité des données
- **Latence** : < 10ms pour commandes critiques

### Localisation multicapteurs
- **Fusion de données** : Kalman filter étendu (EKF)
- **Capteurs** : Odométrie + IMU + Visual SLAM
- **Précision** : ±2cm en environnement structuré

## Résultats et performances

### Métriques de performance
| Critère | Spécification | Résultat obtenu |
|---------|---------------|-----------------|
| Vitesse max | 1 m/s | 1.2 m/s |
| Précision SLAM | ±5cm | ±2cm |
| Autonomie | 4h | 4.5h |

### Validation terrain
✅ **Navigation en extérieur** : Parcours de 500m avec obstacles  
✅ **Cartographie bâtiment** : Mapping complet laboratoire (200m²)  
✅ **Tests de robustesse** : 50h de fonctionnement sans défaillance  
✅ **Démonstration finale** : Présentation aux équipes internationales

## Technologies avancées utilisées

- **ROS 2 Humble** : Architecture robotique nouvelle génération
- **Navigation2** : Stack de navigation professionnelle
- **SLAM Toolbox** : Cartographie et localisation simultanées
- **Gazebo** : Simulation 3D pour tests préliminaires
- **Python/C++** : Développement nodes optimisés
